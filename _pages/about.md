---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>


I am a first-year Ph.D. student at the <a href="https://datascience.hku.hk/">HKU Musketeers Foundation Institute of Data Science (HKU-IDS)</a>, as well as HKU-MMLab, The University of Hong Kong, supervised by Prof. <a href="https://xh-liu.github.io/">Xihui Liu</a>.

I received my B.Eng. Degree from the <a href="https://www.uestc.edu.cn/">University of Electronic Science and Technology of China</a> (UESTC) and MPhil Degree from <a href="https://www.cuhk.edu.cn/en">The Chinese University of Hong Kong, Shenzhen</a> (CUHK-SZ), supervised by Prof. <a href="https://scholar.google.com/citations?user=z-rqsR4AAAAJ&hl=zh-CN">Xiaoguang Han</a>. Before joining HKU-IDS, I've spent wonderful time with great minds and interesting friends at <a href="https://www.shlab.org.cn/">Shanghai AI Laboratory</a>.

My current research interests lie in the <strong>Multimodal Large Language Models</strong> and <strong>3D Vision and Robotics (Embodied AI)</strong>. I'm open to potential collaborations, feel free to drop me an email if you are interested in.


# üî• News
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>


<div class='paper-box'><div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='images/2024_cvpr_embodiedscan/embodiedscan.gif' alt="EmbodiedScan: A Holistic Multi-Modal 3D Perception Suite Towards Embodied AI" loading="lazy" width="85%"></div></div>
<div class='paper-box-text' markdown="1">

  <div class="section-subheading article-title mb-0 mt-0">
    <strong>EmbodiedScan: A Holistic Multi-Modal 3D Perception Suite Towards Embodied AI</strong>
  </div>
  <div class="article-style">
    <strong>CVPR 2024</strong> <br>
    <a href="https://tai-wang.github.io/" target="_blank" rel="noopener">Tai Wang</a>*,
    <a href="https://scholar.google.com/citations?user=-zT1NKwAAAAJ&hl=en&oi=ao" target="_blank" rel="noopener">Xiaohan Mao</a>*,
    <strong><u>Chenming Zhu</u></strong>,
    <a href="https://runsenxu.com/" target="_blank" rel="noopener">Runsen Xu</a>,
    <a href="https://openreview.net/profile?id=~Ruiyuan_Lyu1" target="_blank" rel="noopener">Ruiyuan Lyu</a>,
    <a href="https://openreview.net/profile?id=~Peisen_Li1" target="_blank" rel="noopener">Peisen Li</a>,
    <a href="https://xiao-chen.tech/" target="_blank" rel="noopener">Xiao Chen</a>,
    <a href="https://zhangwenwei.cn/" target="_blank" rel="noopener">Wenwei Zhang</a>,
    <a href="https://chenkai.site/" target="_blank" rel="noopener">Kai Chen</a>,
    <a href="https://tianfan.info/" target="_blank" rel="noopener">Tianfan Xue</a>,
    <a href="https://xh-liu.github.io/" target="_blank" rel="noopener">Xihui Liu</a>,
    <a href="https://www.mvig.org/" target="_blank" rel="noopener">Cewu Lu</a>,
    <a href="http://dahua.site/" target="_blank" rel="noopener">Dahua Lin</a>,
    <a href="https://oceanpang.github.io/" target="_blank" rel="noopener">Jiangmiao Pang</a>‚Ä†
  </div>
  <div class="stream-meta article-metadata"> 
  </div>
  <div class="btn-links">
    <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://tai-wang.github.io/embodiedscan/" target="_blank" rel="noopener">
      Project Page
    </a>
    <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2312.16170" target="_blank" rel="noopener">
      arXiv
    </a>
    <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/OpenRobotLab/EmbodiedScan" target="_blank" rel="noopener">
      Code & Data
    </a>
    <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://mp.weixin.qq.com/s/__cubd_YlvZrTvDHyLI-ow" target="_blank" rel="noopener">
      ‰∏≠ÊñáËß£ËØª
    </a>
  </div>
</div>
</div>


<!-- EmbodiedScan -->
<div class="media stream-item">
  <div class="media-body">
    <div class="section-subheading article-title mb-0 mt-0">
      <strong>EmbodiedScan: A Holistic Multi-Modal 3D Perception Suite Towards Embodied AI</strong>
    </div>
    <div class="article-style">
      <strong>CVPR 2024</strong> <br>
      <a href="https://tai-wang.github.io/" target="_blank" rel="noopener">Tai Wang</a>*,
      <a href="https://scholar.google.com/citations?user=-zT1NKwAAAAJ&hl=en&oi=ao" target="_blank" rel="noopener">Xiaohan Mao</a>*,
      <a href="https://scholar.google.com/citations?user=QabwS_wAAAAJ&hl=en&oi=ao" target="_blank" rel="noopener">Chenming Zhu</a>*,
      <a href="https://runsenxu.com/" target="_blank" rel="noopener">Runsen Xu</a>,
      <a href="https://openreview.net/profile?id=~Ruiyuan_Lyu1" target="_blank" rel="noopener">Ruiyuan Lyu</a>,
      <a href="https://openreview.net/profile?id=~Peisen_Li1" target="_blank" rel="noopener">Peisen Li</a>,
      <strong><u>Xiao Chen</u></strong>, <br>
      <a href="https://zhangwenwei.cn/" target="_blank" rel="noopener">Wenwei Zhang</a>,
      <a href="https://chenkai.site/" target="_blank" rel="noopener">Kai Chen</a>,
      <a href="https://tianfan.info/" target="_blank" rel="noopener">Tianfan Xue</a>,
      <a href="https://xh-liu.github.io/" target="_blank" rel="noopener">Xihui Liu</a>,
      <a href="https://www.mvig.org/" target="_blank" rel="noopener">Cewu Lu</a>,
      <a href="http://dahua.site/" target="_blank" rel="noopener">Dahua Lin</a>,
      <a href="https://oceanpang.github.io/" target="_blank" rel="noopener">Jiangmiao Pang</a>‚Ä†
    </div>
    <div class="stream-meta article-metadata"> 
    </div>
    <div class="btn-links">
      <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://tai-wang.github.io/embodiedscan/" target="_blank" rel="noopener">
        Project Page
      </a>
      <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2312.16170" target="_blank" rel="noopener">
        arXiv
      </a>
      <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/OpenRobotLab/EmbodiedScan" target="_blank" rel="noopener">
        Code & Data
      </a>
      <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://mp.weixin.qq.com/s/__cubd_YlvZrTvDHyLI-ow" target="_blank" rel="noopener">
        ‰∏≠ÊñáËß£ËØª
      </a>
    </div>
  </div>
  <div class="ml-3">
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='images/2024_cvpr_embodiedscan/embodiedscan.gif' alt="EmbodiedScan: A Holistic Multi-Modal 3D Perception Suite Towards Embodied AI" loading="lazy"></div></div>
  </div>
</div>

- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**

# üéñ Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üìñ Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.
